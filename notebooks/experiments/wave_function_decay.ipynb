{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('..', '..')))\n",
    "from src import *\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from numba import njit\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partially fixed, may need to post select eigenvectors with a maximum in some central \n",
    "# region to reduce impact of poorly sampled distances\n",
    "\n",
    "@njit\n",
    "def accumulate_centred_probabilities(data, eigenvectors, L):\n",
    "    for i, arr in enumerate(eigenvectors):\n",
    "        central_index = np.argmax(arr)\n",
    "        for (j, e) in enumerate(arr):\n",
    "            data[j - central_index + (L-1)] += e\n",
    "\n",
    "def produce_data(p, L, realizations):\n",
    "    data = np.zeros(2*(L-1) + 1)\n",
    "    for _ in range(realizations):\n",
    "        ness_correlation = C_NESS(0, 0, A(L, p))\n",
    "        _, eigenvectors = np.linalg.eig(ness_correlation)\n",
    "        accumulate_centred_probabilities(data, np.abs(eigenvectors.T)**2, L)\n",
    "    return data / (realizations*L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 500\n",
    "ps = [0.5, 0.7, 0.9, 1.0, 1.2, 1.4, 1.7, 2.0, 3.0, 5.0]\n",
    "realizations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(map(lambda p: produce_data(p, L, realizations), ps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "fit_lower_bound = 50\n",
    "fit_upper_bound = 500\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "grads = np.zeros(len(data))\n",
    "for i, y in enumerate(data):\n",
    "    x = np.abs(np.arange(2*L-1)-L)\n",
    "    g, c = fit_log_log(x, y, np.arange(fit_lower_bound, fit_upper_bound))\n",
    "    grads[i] = -g\n",
    "    ax[0].plot(x, y, linewidth=2.5, label=r\"$p = {}, a = {}, c = {}$\".format(\n",
    "        ps[i], round(-g, 3), round(math.exp(c)), 3))\n",
    "    linear_x_axis = np.arange(fit_lower_bound/2, fit_upper_bound/2)\n",
    "    ax[0].plot(linear_x_axis, math.exp(c)*(linear_x_axis**g))\n",
    "ax[0].set_xlabel(r\"$|i-i_\\mathrm{max}|$\")\n",
    "ax[0].set_ylabel(r\"$\\left\\langle|\\psi(i-i_\\mathrm{max})|^2\\right\\rangle$\")\n",
    "ax[0].set_yscale('log')\n",
    "#ax[0].set_xscale('log')\n",
    "ax[0].set_title(r'$L = 1000, \\mathrm{realizations} = 100, y(x) \\approx cx^a$')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(ps, grads, label=r\"$y(p)=a(p)$\")\n",
    "ax[1].plot(ps, ps, label=r\"$y(p)=p$\")\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../../data/wave_function_day_data.npy\", data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('numba')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3ea23f975fe4e610a4ed32fc8f3f3cbfe2f222a882b375ad37ce039218ed78d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
